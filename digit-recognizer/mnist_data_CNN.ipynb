{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shalundia/Kaggle/blob/master/digit-recognizer/mnist_data_CNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "W3J_7ayNEQzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2b8538f-10fd-4a65-9e55-a38d4870ad22"
      },
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/shalundia/Kaggle\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Kaggle'...\n",
            "remote: Counting objects: 87, done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 87 (delta 42), reused 63 (delta 24), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2lDJHchTBVqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "308c4104-a652-4253-94f7-aeabc6ca00ae"
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs,steps_per_epoch=2000\n",
        "                              )\n",
        "'''model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))'''\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "2000/2000 [==============================] - 111s 55ms/step - loss: 0.2536 - acc: 0.9217\n",
            "Epoch 2/12\n",
            "2000/2000 [==============================] - 111s 55ms/step - loss: 0.1098 - acc: 0.9677\n",
            "Epoch 3/12\n",
            "2000/2000 [==============================] - 111s 55ms/step - loss: 0.0919 - acc: 0.9735\n",
            "Epoch 4/12\n",
            "2000/2000 [==============================] - 111s 55ms/step - loss: 0.0841 - acc: 0.9764\n",
            "Epoch 5/12\n",
            "2000/2000 [==============================] - 110s 55ms/step - loss: 0.0759 - acc: 0.9781\n",
            "Epoch 6/12\n",
            "2000/2000 [==============================] - 111s 56ms/step - loss: 0.0727 - acc: 0.9794\n",
            "Epoch 7/12\n",
            "2000/2000 [==============================] - 109s 54ms/step - loss: 0.0702 - acc: 0.9805\n",
            "Epoch 8/12\n",
            "2000/2000 [==============================] - 106s 53ms/step - loss: 0.0671 - acc: 0.9814\n",
            "Epoch 9/12\n",
            "2000/2000 [==============================] - 106s 53ms/step - loss: 0.0676 - acc: 0.9815\n",
            "Epoch 10/12\n",
            "2000/2000 [==============================] - 105s 53ms/step - loss: 0.0661 - acc: 0.9821\n",
            "Epoch 11/12\n",
            "2000/2000 [==============================] - 106s 53ms/step - loss: 0.0642 - acc: 0.9827\n",
            "Epoch 12/12\n",
            "2000/2000 [==============================] - 105s 53ms/step - loss: 0.0618 - acc: 0.9827\n",
            "Test loss: 0.020901386906687365\n",
            "Test accuracy: 0.9935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aNenhut-C9pa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yo7XNkvGBWke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "test=np.loadtxt(open('Kaggle/digit-recognizer/test.csv', \"rb\"), delimiter=\",\", skiprows=1)\n",
        "\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    test = test.reshape(test.shape[0], 1, img_rows, img_cols)\n",
        "else:\n",
        "    test = test.reshape(test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "test = test.astype('float32')\n",
        "test /= 255\n",
        "\n",
        "prediction=model.predict(test,batch_size=batch_size)\n",
        "\n",
        "submission=np.argmax(prediction,axis=1)\n",
        "\n",
        "sub=pd.DataFrame()\n",
        "sub['ImageId']=np.arange(start=1,stop=(len(test)+1))\n",
        "sub['Label']=submission\n",
        "sub.to_csv(\"submission.csv\",index=False)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1R9GbIS4EaYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}